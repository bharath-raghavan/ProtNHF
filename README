# Conditional protein sequence generation and protein editting with Neural Hamiltonian Flows

This repository contains a prototype model developed during my postdoctoral research at Oak Ridge National Laboratory with David Rogers. The model explores using Neural Hamiltonian Flows (NHFs) to generate protein sequences. While not yet production- or publication-ready, it demonstrates that this architecture potentially allows conditional protein generation but inducing mutantions on singles residues or groups of residues without having to retrain the base model. This allows for protein/peptide engineering with AI at a very high level.

## Introduction

Prediciting a protein sequence which would correpsond to a protein with a valid folding pattern is in general a non-trivial task. In recent years, novel neural network architecures combined with generative AI methods like diffusion have lead to multiple AI models that can accurately generate valid protein sequences. Although this in itself has applications in the pharmaceutical and biotech industries, what is really required is a reliable way to generate sequences conditioned on some desired properties (like binding affinity, secondary structure, etc.). Although AI models have been shown to be able to generate protein sequences conditionally, this would often require expensive retraining of the unconditional model to include the desired condition. An improvement to this is the recently published Chroma model. Here a diffusion model is trained to predict protein sequences unconditionally. Conditional generation is achieved by applying external constraints only during the sampling. The work showed that these constraints can be analytical functions or separately trained neural networks.

All these models generate protein sequences de novo, i.e., without existing natural templates. However often in the drug design process, what is desired is to generated leads around a specific protein candidate. This means changing one or a number of residues of the protein, without disturbing the overall folding pattern. This sort of 'protein editing' cannot be achieved with current generative AI models. In this work, we show that it is possible to achieve this using NHFs.

NHFs are a type of generative model where Hamiltonian transformations are treated as a normalizing flow. As reported in Souveton et. al. Hamiltonian dynamics have four main advantages that make them ideal for normalizing flows: (i) they are smooth and easily invertible, as one just needs to reverse the timestep to go backward in time; (ii) as symplectic transformations, they are volume-preserving, meaning that their Jacobian determinant is exactly equal to 1; (iii) they have empirically demonstrated their ability to model complex distributions; (iv) they are Physics-inspired, making them highly interpretable in many cases. However, we argue another advantage exists, that makes them particularly relevant to conditional protein generation. This is that biased samples can be generated by just adding a bias energy to the Hamiltonian, similar to how biased MD simulations are performed. During training, a distibution p_θ(x,p) is learnt:

p_θ(x,p) ∝ exp(−Hθ​(x,p))

We can add a bias U_bias only at generation to get the conditional probaility distribution:

p_θ^cond(x,p) ∝ exp(−H_θ​(x,p)−U_cond​(x)) ∝ exp(−H_θ​(x,p))exp(−U_cond​(x))

This allows to generated conditional samples from a model trained only on uncoditionally. This is like Chroma. However, what makes this different is that NHFs, just like any other normalizing flow, is reversible. This means that if we have a protein with sequence embedding x_0, we can run the forward process of the HNF and obtain it equivalent in the latent distribution z. We can then take this latent representation and run the reverse process. Of course, if an unbiased reverse process is performed, we get pack x_0. However, if we include a bias in the reverse process we would obtain a different sequence embedding x_1. This should correspond to the protein with largely a similar structure, and folding pattern as the original protein, except with the bias added. For example, if the bias is a columbic replusion term on the a specific residue X, x_1 would correspon to a protein with a simialr folding pattern as x_0, but avoiding the residue X. This is how model allows for editing of proteins to generate leads around a specific candidate during a drug design campaign.
